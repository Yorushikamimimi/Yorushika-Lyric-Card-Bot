import asyncio
import random
from playwright.async_api import async_playwright, Page

# === é…ç½®åŒº ===
# ä½ çš„ä»£ç†åœ°å€
PROXY_URL = "http://127.0.0.1:26001"
ARTIST_URL = "https://www.uta-net.com/artist/22669/"
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"


# =============

class YorushikaCrawler:
    def __init__(self):
        self.browser = None
        self.playwright = None

    async def start(self):
        print(">>> [Crawler] Starting browser...")
        self.playwright = await async_playwright().start()
        # ä¾ç„¶ä½¿ç”¨ headless=True ä¿æŒé™é»˜
        self.browser = await self.playwright.chromium.launch(
            channel="msedge",
            headless=True,
            proxy={"server": PROXY_URL}
        )

    async def stop(self):
        if self.browser:
            await self.browser.close()
            print(">>> [Crawler] Browser closed.")
        if self.playwright:
            await self.playwright.stop()

    async def _goto_with_retry(self, page: Page, url: str, retries=3):
        """ ã€æ ¸å¿ƒå°è£…ã€‘å¸¦é‡è¯•æœºåˆ¶çš„é¡µé¢è·³è½¬ """
        for i in range(retries):
            try:
                print(f"    -> Accessing {url} (Attempt {i + 1}/{retries})...")
                # timeout=30000 (30ç§’è¶…æ—¶)
                await page.goto(url, wait_until="domcontentloaded", timeout=30000)
                return  # æˆåŠŸåˆ™ç›´æ¥è¿”å›
            except Exception as e:
                print(f"    âš ï¸ Connection failed: {e}")
                if i < retries - 1:
                    wait_time = (i + 1) * 2  # å¤±è´¥ç­‰å¾… 2ç§’, 4ç§’...
                    print(f"    â³ Waiting {wait_time}s before retry...")
                    await asyncio.sleep(wait_time)
                else:
                    raise e  # æ¬¡æ•°ç”¨å°½ï¼ŒæŠ›å‡ºå¼‚å¸¸

    async def get_random_song_url(self) -> str:
        page = await self.browser.new_page(user_agent=USER_AGENT)
        try:
            print(f">>> [Crawler] 1. Fetching song list...")
            await self._goto_with_retry(page, ARTIST_URL)

            # ç®€å•çš„æ»šåŠ¨
            await page.mouse.wheel(0, 3000)
            await asyncio.sleep(1)  # ç¨å¾®ç­‰ä¸€ä¸‹æ¸²æŸ“

            # ç­‰å¾…é“¾æ¥
            await page.wait_for_selector("a[href*='/song/']", timeout=10000)
            elements = await page.locator("a[href*='/song/']").all()

            song_urls = []
            for el in elements:
                href = await el.get_attribute("href")
                if href and "/song/" in href:
                    song_urls.append(f"https://www.uta-net.com{href}")

            # å»é‡
            unique = list(set(song_urls))
            if not unique:
                raise Exception("No songs found (List empty)!")

            selected = random.choice(unique)
            print(f"âœ… [Crawler] Found {len(unique)} songs. Selected: {selected}")
            return selected

        finally:
            await page.close()

    async def get_lyric_by_url(self, url: str) -> str:
        # ã€æ‹ŸäººåŒ–ã€‘åœ¨è¯·æ±‚è¯¦æƒ…é¡µä¹‹å‰ï¼Œæ•…æ„ä¼‘æ¯ 2 ç§’ï¼Œé˜²æ­¢è¢«æœåŠ¡å™¨åˆ¤å®šä¸ºæœºå™¨äºº
        print(">>> [Crawler] ğŸ›Œ Resting for 2s...")
        await asyncio.sleep(2)

        page = await self.browser.new_page(user_agent=USER_AGENT)
        try:
            print(f">>> [Crawler] 2. Fetching lyric...")
            await self._goto_with_retry(page, url)

            await page.wait_for_selector("#kashi_area", timeout=10000)
            raw = await page.locator("#kashi_area").inner_text()

            # ç®€å•æ¸…æ´—
            lines = [line.strip() for line in raw.split('\n') if line.strip()]

            # ä¸ºäº†å¡ç‰‡å¥½çœ‹ï¼Œæˆ‘ä»¬åªå–æ¯”è¾ƒâ€œæ•´é½â€çš„ä¸€æ®µ
            # æ¯”å¦‚å–ä¸­é—´çš„å‡ å¥ï¼Œæˆ–è€…ç›´æ¥å–å‰å‡ å¥
            if len(lines) > 5:
                # ç¨å¾®å–ä¸€ç‚¹ç¨å¾®é•¿ä¸€ç‚¹çš„æ­Œè¯ï¼Œå¤ªçŸ­çš„ä¸å¥½çœ‹
                preview = "\n".join(lines[:8])
            else:
                preview = "\n".join(lines)

            print(f"âœ… [Crawler] Lyric captured! ({len(preview)} chars)")
            return preview

        finally:
            await page.close()


# --- æµ‹è¯•å…¥å£ ---
async def test_run():
    bot = YorushikaCrawler()
    await bot.start()
    try:
        url = await bot.get_random_song_url()
        lyric = await bot.get_lyric_by_url(url)
        print("\n" + "=" * 30)
        print(lyric)
        print("=" * 30)
    except Exception as e:
        print(f"âŒ FATAL ERROR: {e}")
    finally:
        await bot.stop()


if __name__ == "__main__":
    asyncio.run(test_run())